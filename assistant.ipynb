{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\admin\\miniconda3\\envs\\tf\\lib\\site-packages (0.28.1)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\admin\\miniconda3\\envs\\tf\\lib\\site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\miniconda3\\envs\\tf\\lib\\site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\admin\\miniconda3\\envs\\tf\\lib\\site-packages (from openai) (3.8.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\miniconda3\\envs\\tf\\lib\\site-packages (from requests>=2.20->openai) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\miniconda3\\envs\\tf\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\miniconda3\\envs\\tf\\lib\\site-packages (from requests>=2.20->openai) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\miniconda3\\envs\\tf\\lib\\site-packages (from requests>=2.20->openai) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\admin\\miniconda3\\envs\\tf\\lib\\site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\admin\\miniconda3\\envs\\tf\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\admin\\miniconda3\\envs\\tf\\lib\\site-packages (from aiohttp->openai) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\admin\\miniconda3\\envs\\tf\\lib\\site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\admin\\miniconda3\\envs\\tf\\lib\\site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\admin\\miniconda3\\envs\\tf\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\miniconda3\\envs\\tf\\lib\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import time\n",
    "\n",
    "api_key = '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'\n",
    "last_request_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_limited_assistant(prompt):\n",
    "    global last_request_time\n",
    "    elapsed_time = time.time() - last_request_time\n",
    "    \n",
    "    if elapsed_time < 5:\n",
    "        time.sleep(5-elapsed_time)\n",
    "        \n",
    "    last_request_time = time.time()\n",
    "    \n",
    "    openai.api_key = api_key\n",
    "    \n",
    "    response_text = \"\"\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            response = openai.Completion.create(\n",
    "                engine = \"text-davinci-002\",\n",
    "                prompt=prompt,\n",
    "                max_tokens = 50\n",
    "            )\n",
    "            \n",
    "            current_response = response.choices[0].text.strip()\n",
    "            \n",
    "            response_text += current_response\n",
    "            \n",
    "            if '.' in current_response or len(response_text.split()) >= 50:\n",
    "                break\n",
    "            \n",
    "            prompt = current_response\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during API request: {e}\")\n",
    "        \n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Hello! What can I help you with today?\n",
      "You:  can help me with math\n",
      "Assistant:  I'm sorry, but I am focused on history and unable to assist with inquiries outside this field.\n",
      "You:  what is malaysia independec=nce day\n",
      "Assistant:  Malaysia's Independence Day is celebrated on August 31st. This holiday commemorates the day when Malaysia became an independent and sovereign nation in 1957.\n",
      "You:  what is 1+1\n",
      "Assistant:  I'm sorry, but I am a history expert and am unable to help with inquiries outside this field.\n",
      "You:  what is the component of water\n",
      "Assistant:  I'm sorry, but I am not able to help with questions outside of history.\n",
      "You:  can u list down the important figure in ww2\n",
      "Assistant:  I am a historical expert. I can list some important figures in World War II, but I am not a math expert and cannot help with mathematical questions.\n",
      "You:  exit\n",
      "Assistant: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Assistant: Hello! What can I help you with today?\")\n",
    "    \n",
    "    conversation_history = \"\"\n",
    "    instructions = [\n",
    "        \"Instruction 1: You are a knowledgeable history expert, providing detailed and accurate answers to history-related questions.\",\n",
    "        \"Instruction 2: If the query is related to a different subject (e.g., math, science, literature), clearly state that you are focused on history and unable to assist with inquiries outside this field.\",\n",
    "        \"Instruction 3: If the question pertains to an unrelated topic, kindly express that it falls outside your field of expertise.\",\n",
    "        \"Instruction 4: If the user asks who or what you are, say you are a historical expert.\"\n",
    "    ]\n",
    "    instructions_str = '\\n'.join(instructions)\n",
    "    while True:\n",
    "        user_input = input(\"You:\")\n",
    "        if not user_input.strip():\n",
    "            print(\"Assistant: Its empty!\")\n",
    "            continue\n",
    "        print(\"You: \",user_input)\n",
    "        \n",
    "        if user_input.lower()==\"exit\":\n",
    "            print(\"Assistant: Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        conversation_history += f\"You:{user_input}\\n\"\n",
    "        \n",
    "        prompt = instructions_str + conversation_history + \"Assistant:\"\n",
    "        \n",
    "        response = rate_limited_assistant(prompt)\n",
    "        \n",
    "        conversation_history += f\"Assistant:\\n\"\n",
    "        \n",
    "        print(\"Assistant: \", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
